{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORES = [\"cornflowerblue\", \"midnightblue\", \"forestgreen\", \"brown\"]\n",
    "\n",
    "# Ficheros\n",
    "fichero_fondo_06 = 'data/bottom_06011702.csv'\n",
    "fichero_fondo_16 = 'data/bottom_16061107.csv'\n",
    "fichero_fondo_26 = 'data/bottom_26040406.csv'\n",
    "fichero_fondo_19 = 'data/bottom_103319.csv'\n",
    "fichero_fondo_22 = 'data/bottom_103322.csv'\n",
    "fichero_superficie_06 = 'data/surface_06010702.csv'\n",
    "fichero_superficie_16 = 'data/surface_16061107.csv'\n",
    "fichero_superficie_26 = 'data/surface_26040604.csv'\n",
    "fichero_superficie_32 = 'data/surface_103326.csv'\n",
    "fichero_superficie_29 = 'data/surface_103329.csv'\n",
    "\n",
    "fichero_ambiente = 'data/air_temp_2022-2023.csv'\n",
    "fichero_ambiente_13 = 'data/air_temp_103313.csv'\n",
    "\n",
    "fichero_nivel = 'data/lagoon_level-data-20_07_2023-11_04_02.csv'\n",
    "fichero_nivel_lag = 'data/lagoon_level.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Tª fondo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fondo_06 = pd.read_csv(fichero_fondo_06)\n",
    "data_fondo_06.rename(columns={'fondo s2': 'fondo'}, inplace=True)\n",
    "\n",
    "data_fondo_16= pd.read_csv(fichero_fondo_16)\n",
    "\n",
    "data_fondo_26 = pd.read_csv(fichero_fondo_26)\n",
    "data_fondo_26.rename(columns={'fondo s22': 'fondo'}, inplace=True)\n",
    "\n",
    "data_fondo_19 = pd.read_csv(fichero_fondo_19)\n",
    "data_fondo_19.rename(columns={'fondo s22': 'fondo'}, inplace=True)\n",
    "\n",
    "data_fondo_22 = pd.read_csv(fichero_fondo_22)\n",
    "data_fondo_22.rename(columns={'fondo s2': 'fondo'}, inplace=True)\n",
    "\n",
    "data_fondo = pd.concat([data_fondo_16,\n",
    "                        data_fondo_06,\n",
    "                        data_fondo_26, \n",
    "                        data_fondo_19,\n",
    "                        data_fondo_22], ignore_index=True)\n",
    "data_fondo.rename(columns={'Time': 'date'}, inplace=True)\n",
    "\n",
    "data_fondo['date'] = pd.to_datetime(data_fondo['date'])  \n",
    "data_fondo = data_fondo.sort_values(by='date')\n",
    "\n",
    "# Reiniciar los índices después de ordenar\n",
    "data_fondo = data_fondo.reset_index(drop=True)\n",
    "\n",
    "print(data_fondo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay valores nulos y eliminandolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_before = data_fondo['fondo'].isna().sum()\n",
    "\n",
    "data_fondo = data_fondo.dropna(subset=['fondo'])\n",
    "\n",
    "nan_count_after = data_fondo['fondo'].isna().sum()\n",
    "\n",
    "print(\"Cantidad de NaN en 'fondo' antes de la eliminación:\", nan_count_before)\n",
    "print(\"Cantidad de NaN en 'fondo' después de la eliminación:\", nan_count_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay fechas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay_duplicados = data_fondo['date'].duplicated().any()\n",
    "\n",
    "# if hay_duplicados:\n",
    "#     print(\"Hay fechas duplicadas en la columna 'date'.\")\n",
    "# else:\n",
    "#     print(\"No hay fechas duplicadas en la columna 'date'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_fondo.info())\n",
    "\n",
    "# data_fondo = data_fondo.groupby('date').mean(numeric_only = True).reset_index()\n",
    "\n",
    "# data_fondo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Tª superficie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_superficie_06 = pd.read_csv(fichero_superficie_06)\n",
    "data_superficie_06.rename(columns={'superficie s1': 'superficie'}, inplace=True)\n",
    "\n",
    "data_superficie_16= pd.read_csv(fichero_superficie_16)\n",
    "\n",
    "data_superficie_26 = pd.read_csv(fichero_superficie_26)\n",
    "data_superficie_26.rename(columns={'superficie s1': 'superficie'}, inplace=True)\n",
    "\n",
    "data_superficie_32 = pd.read_csv(fichero_superficie_32)\n",
    "data_superficie_32.rename(columns={'superficie s1': 'superficie'}, inplace=True)\n",
    "\n",
    "data_superficie_29 = pd.read_csv(fichero_superficie_29)\n",
    "data_superficie_29.rename(columns={'superficie s11': 'superficie'}, inplace=True)\n",
    "\n",
    "data_superficie = pd.concat([data_superficie_16,\n",
    "                             data_superficie_06,\n",
    "                             data_superficie_26,\n",
    "                             data_superficie_29,\n",
    "                             data_superficie_32], ignore_index=True)\n",
    "data_superficie.rename(columns={'Time': 'date'}, inplace=True)\n",
    "\n",
    "data_superficie['date'] = pd.to_datetime(data_superficie['date'])  \n",
    "data_superficie = data_superficie.sort_values(by='date')\n",
    "\n",
    "# Reiniciar los índices después de ordenar\n",
    "data_superficie = data_superficie.reset_index(drop=True)\n",
    "\n",
    "print(data_superficie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay valores nulos y eliminandolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_before = data_superficie['superficie'].isna().sum()\n",
    "\n",
    "data_superficie = data_superficie.dropna(subset=['superficie'])\n",
    "\n",
    "nan_count_after = data_superficie['superficie'].isna().sum()\n",
    "\n",
    "print(\"Cantidad de NaN en 'superficie' antes de la eliminación:\", nan_count_before)\n",
    "print(\"Cantidad de NaN en 'superficie' después de la eliminación:\", nan_count_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay fechas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay_duplicados = data_superficie['date'].duplicated().any()\n",
    "\n",
    "# if hay_duplicados:\n",
    "#     print(\"Hay fechas duplicadas en la columna 'date'.\")\n",
    "# else:\n",
    "#     print(\"No hay fechas duplicadas en la columna 'date'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_superficie.info())\n",
    "\n",
    "# data_superficie = data_superficie.groupby('date').mean(numeric_only = True).reset_index()\n",
    "\n",
    "# data_superficie.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Tª ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ambiente_22 = pd.read_csv(fichero_ambiente)\n",
    "data_ambiente_22.rename(columns={'lama.mean': 'ambiente'}, inplace=True)\n",
    "data_ambiente_22.rename(columns={'Time': 'date'}, inplace=True)\n",
    "data_ambiente_22['date'] = pd.to_datetime(data_ambiente_22['date'], format=\"%d/%m/%Y, %H:%M:%S\")  \n",
    "\n",
    "data_ambiente_13 = pd.read_csv(fichero_ambiente_13)\n",
    "data_ambiente_13.rename(columns={'TEMPERATURA AMBIENTE': 'ambiente'}, inplace=True)\n",
    "data_ambiente_13.rename(columns={'Time': 'date'}, inplace=True)\n",
    "data_ambiente_13['date'] = pd.to_datetime(data_ambiente_13['date'], format=\"%Y-%m-%d %H:%M:%S\")  \n",
    "\n",
    "\n",
    "data_ambiente = pd.concat([data_ambiente_22,\n",
    "                           data_ambiente_13], ignore_index=True)\n",
    "\n",
    "data_ambiente = data_ambiente.sort_values(by='date')\n",
    "\n",
    "# Reiniciar los índices después de ordenar\n",
    "data_ambiente = data_ambiente.reset_index(drop=True)\n",
    "\n",
    "print(data_ambiente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay valores nulos y eliminandolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_before = data_ambiente['ambiente'].isna().sum()\n",
    "\n",
    "data_ambiente = data_ambiente.dropna(subset=['ambiente'])\n",
    "\n",
    "nan_count_after = data_ambiente['ambiente'].isna().sum()\n",
    "\n",
    "print(\"Cantidad de NaN en 'ambiente' antes de la eliminación:\", nan_count_before)\n",
    "print(\"Cantidad de NaN en 'ambiente' después de la eliminación:\", nan_count_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay fechas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay_duplicados = data_fondo['date'].duplicated().any()\n",
    "\n",
    "# if hay_duplicados:\n",
    "#     print(\"Hay fechas duplicadas en la columna 'date'.\")\n",
    "# else:\n",
    "#     print(\"No hay fechas duplicadas en la columna 'date'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_ambiente.info())\n",
    "\n",
    "# data_ambiente = data_ambiente.groupby('date').mean(numeric_only = True).reset_index()\n",
    "\n",
    "# data_ambiente.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Nivel del agua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nivel_20 = pd.read_csv(fichero_nivel)\n",
    "data_nivel_20.rename(columns={'Altura lamina ': 'nivel'}, inplace=True)\n",
    "data_nivel_20.rename(columns={'Time': 'date'}, inplace=True)\n",
    "data_nivel_20['date'] = pd.to_datetime(data_nivel_20['date'], format=\"%d/%m/%Y, %H:%M:%S\")  \n",
    "\n",
    "\n",
    "data_nivel_lag = pd.read_csv(fichero_nivel_lag)\n",
    "data_nivel_lag.rename(columns={'NIVEL CADA HORA': 'nivel'}, inplace=True)\n",
    "data_nivel_lag.rename(columns={'Time': 'date'}, inplace=True)\n",
    "data_nivel_lag['date'] = pd.to_datetime(data_nivel_lag['date'], format=\"%Y-%m-%d %H:%M:%S\")  \n",
    "\n",
    "\n",
    "data_nivel = pd.concat([data_nivel_20,\n",
    "                        data_nivel_lag], ignore_index=True)\n",
    "\n",
    "\n",
    "data_nivel = data_nivel.sort_values(by='date')\n",
    "\n",
    "# Reiniciar los índices después de ordenar\n",
    "data_nivel = data_nivel.reset_index(drop=True)\n",
    "\n",
    "print(data_nivel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay valores nulos y eliminandolos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_count_before = data_nivel['nivel'].isna().sum()\n",
    "\n",
    "data_nivel = data_nivel.dropna(subset=['nivel'])\n",
    "\n",
    "nan_count_after = data_nivel['nivel'].isna().sum()\n",
    "\n",
    "print(\"Cantidad de NaN en 'nivel' antes de la eliminación:\", nan_count_before)\n",
    "print(\"Cantidad de NaN en 'nivel' después de la eliminación:\", nan_count_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay fechas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay_duplicados = data_nivel['date'].duplicated().any()\n",
    "\n",
    "# if hay_duplicados:\n",
    "#     print(\"Hay fechas duplicadas en la columna 'date'.\")\n",
    "# else:\n",
    "#     print(\"No hay fechas duplicadas en la columna 'date'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_nivel.info())\n",
    "\n",
    "# data_nivel = data_nivel.groupby('date').mean(numeric_only = True).reset_index()\n",
    "\n",
    "# data_nivel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificación de las fuentes de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_fondo, data_superficie, data_ambiente, data_nivel], ignore_index=True)\n",
    "\n",
    "data = data.sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobando si hay fechas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hay_duplicados = data['date'].duplicated().any()\n",
    "\n",
    "if hay_duplicados:\n",
    "    print(\"Hay fechas duplicadas en la columna 'date'.\")\n",
    "\n",
    "    filas_duplicadas = data[data.duplicated(subset=['date'], keep=False)]\n",
    "\n",
    "    print(\"Filas con fechas duplicadas:\")\n",
    "    print(filas_duplicadas[\"date\"])\n",
    "else:\n",
    "    print(\"No hay fechas duplicadas en la columna 'date'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['superficie'] = data['superficie'].str.replace('°C', '', regex=True).astype(float)\n",
    "# data['fondo'] = data['fondo'].str.replace('°C', '', regex=True).astype(float)\n",
    "# data['ambiente'] = data['ambiente'].str.replace('°C', '', regex=False).astype(float)\n",
    "# data['nivel'] = data['nivel'].str.replace('cm', '', regex=True).astype(float)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_values = data.shape[0]\n",
    "\n",
    "data = data.dropna(subset=[col for col in data.columns if col != 'date'], how='all')\n",
    "\n",
    "print()\n",
    "print('Total de valores NAN:', str(nan_values - data.shape[0]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data.groupby('date').mean(numeric_only = True).reset_index()\n",
    "data_final = data_final[[\"date\",\"fondo\",\"superficie\",\"ambiente\",\"nivel\"]]\n",
    "print(data_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.to_csv('data/datos_laguna_unificados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['date','nivel']]\n",
    "data_final = data.dropna(subset=[col for col in data.columns if col != 'date'], how='all')\n",
    "\n",
    "\n",
    "data_final['fecha_hora'] = pd.to_datetime(data_final['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extraemos el día de la fecha_hora\n",
    "data_final['fecha'] = data_final['fecha_hora'].dt.date\n",
    "\n",
    "# Agrupamos las fechas por día y obtenemos las horas presentes en cada día\n",
    "horas_por_dia = data_final.groupby('fecha')['fecha_hora'].apply(lambda x: x.dt.strftime('%H:%M:%S').tolist())\n",
    "\n",
    "# Crear una figura y ejes para la gráfica\n",
    "fig, ax = plt.subplots(figsize=(15, 20))\n",
    "\n",
    "# Graficar las horas presentes para cada día\n",
    "for fecha, horas in horas_por_dia.items():\n",
    "    ax.plot([fecha] * len(horas), horas, 'o', label=fecha)\n",
    "\n",
    "# Configurar la apariencia de la gráfica\n",
    "plt.xlabel('Día')\n",
    "plt.ylabel('Horas presentes')\n",
    "plt.title('Horas presentes para cada día')\n",
    "\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
